{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Named_Entity_Recognition_CRF_predict_final_version (no_tocar).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daquarti/AI/blob/main/Named_Entity_Recognition_CRF_Bidireccional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpeL-KLsCwh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e13c9554-b2f5-4490-9399-eade77b6c318"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXe9kIsmC8mr"
      },
      "source": [
        "path = \"/content/gdrive/My Drive/NLP/antecedentes/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kujQ2xP7D6gs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "483d66df-4350-478a-b311-8b03f59713a4"
      },
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-6bxj5lz9\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-6bxj5lz9\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=8810902f64554d02ac104a0b46d8bfcb252687a6d4aa001f629d58986c6004c0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5n6tsuc3/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y1nLN5t9ZAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8c84cdf4-9d2f-48de-e541-a2b8725b2e94"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import  crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "\n",
        "\n",
        "# To load the model\n",
        "custom_objects={'CRF'                 : CRF,\n",
        "              'crf_loss'            : crf_loss,\n",
        "              'crf_viterbi_accuracy': crf_viterbi_accuracy}\n",
        "\n",
        "# To load a persisted model that uses the CRF layer \n",
        "model = load_model(path + 'my_model_antecedentes_junio_20.h5', custom_objects = custom_objects)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nYLts1Y4nie"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK3Q4_bpjdXA"
      },
      "source": [
        "import json\n",
        "dics = json.load(open(path + 'dic_predict_crf_june_19.json', 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60XbFRx9s9yW"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfid2rtsjq-V"
      },
      "source": [
        "word2idx = dics['word2idx']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CVun0kkTLq"
      },
      "source": [
        "idx2tag = dics['idx2tag']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOqIhlvulkZm"
      },
      "source": [
        "tag2idx = dics['tag2idx']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlcGeXG-sjjo"
      },
      "source": [
        "word_tokenizer = tf.keras.preprocessing.text.text_to_word_sequence "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVYEvN9q4d-5"
      },
      "source": [
        "n_words = 99170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABV-_otUrr7"
      },
      "source": [
        "def prediccion (oracion):\n",
        "  from keras.preprocessing.sequence import pad_sequences\n",
        "  oracion_split = word_tokenizer (oracion)\n",
        "  oracion_index = []\n",
        "  for w in oracion_split:\n",
        "    try:\n",
        "      oracion_index.append(word2idx[w])\n",
        "    except:\n",
        "      oracion_index.append(word2idx['que'])\n",
        "  oracion_final = pad_sequences(maxlen=86, sequences=[oracion_index], padding=\"post\",value=n_words - 1)\n",
        "  return oracion_final, oracion_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72fasgA7WAEk"
      },
      "source": [
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[str(p_i)])\n",
        "        out.append(out_i)\n",
        "    etiquetas = out\n",
        "    tupla = list (zip (x_predict[1], etiquetas[0]))\n",
        "    return tupla\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1jG0EjlwCcU"
      },
      "source": [
        "def decoder (tupla):\n",
        "  antecedente = []\n",
        "  combinado = []\n",
        "  for c, x in enumerate (tupla):\n",
        "    if x[1] == 'B-antecedentes':\n",
        "      try:\n",
        "        if lista[c+1][1] != 'I-antecedentes':\n",
        "          antecedente.append (x[0])\n",
        "      except:\n",
        "        pass\n",
        "      try:\n",
        "        if lista[c+1][1] == 'I-antecedentes' and lista[c+2][1] == 'I-antecedentes':\n",
        "          first = x[0]\n",
        "          second = lista[c+1][0]\n",
        "          third = lista[c+2][0]\n",
        "          total = first + \" \" + second + \" \" + third\n",
        "          combinado.append (total)\n",
        "      except:\n",
        "        pass\n",
        "      try:\n",
        "        if lista[c+1][1] == 'I-antecedentes':\n",
        "          first = x[0]\n",
        "          second = lista[c+1][0]\n",
        "          total = first + \" \" + second\n",
        "          combinado.append (total)\n",
        "      except:\n",
        "        pass\n",
        "        antecedente.append (x[0])\n",
        "  final = list(set(antecedente + combinado))\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdRu_0fwV1Ha"
      },
      "source": [
        "x_predict = prediccion (\"PAciente hipertenso, obeso con antecedente de estenosis aórtica severa\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ism-5epCq8xC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9771f8e7-2705-43ad-f5da-61679e90c9ef"
      },
      "source": [
        "test_pred = model.predict(x_predict[0], verbose=1)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 36ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2vTYKTs3Jy"
      },
      "source": [
        "lista = pred2label(test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKhztVnV7GE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b01fb65c-dafc-4bdf-a324-38966e532582"
      },
      "source": [
        "decoder(lista)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['epoc', 'dislipemia', 'dbt', 'estenosis aórtica', 'icc', 'obeso']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0oUVxPA7GMq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "21ad88db-21d1-4fa1-d364-5913f48ba7f5"
      },
      "source": [
        "lista "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('paciente', 'O'),\n",
              " ('hipertenso', 'B-antecedentes'),\n",
              " ('obeso', 'B-antecedentes'),\n",
              " ('con', 'O'),\n",
              " ('antecedente', 'O'),\n",
              " ('de', 'O'),\n",
              " ('estenosis', 'B-antecedentes'),\n",
              " ('aórtica', 'I-antecedentes'),\n",
              " ('severa', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rcuIqS7GRw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}